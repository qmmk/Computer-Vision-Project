Index: utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from wand.image import Image\r\nimport numpy as np\r\nimport cv2\r\nimport csv\r\nimport lensfunpy\r\n\r\nlista_cvs = './dataset/data.csv'\r\n\r\n\r\ndef carica_lista_cvs():\r\n    lista_titoli = []\r\n    lista_immagini = []\r\n    lista_stanze = []\r\n    with open(lista_cvs) as csv_file:\r\n        csv_reader = csv.reader(csv_file, delimiter=',')\r\n        line_count = 0\r\n        for row in csv_reader:\r\n            lista_immagini.append(row[3])\r\n            lista_titoli.append(row[0])\r\n            lista_stanze.append(row[2])\r\n\r\n    return lista_titoli, lista_immagini, lista_stanze\r\n\r\n\r\ndef compute_histogram(img):\r\n    planes = []\r\n    if len(img.shape) == 3:\r\n        h, w, d = img.shape\r\n        h_w = h * w\r\n        if d == 3:\r\n            p1 = img[:, :, 0]\r\n            p2 = img[:, :, 1]\r\n            p3 = img[:, :, 2]\r\n            planes = [p1, p2, p3]\r\n        else:\r\n            planes = [img]\r\n\r\n    if len(img.shape) == 2:\r\n        h_w, d = img.shape\r\n        if d == 3:\r\n            p1 = img[:, 0]\r\n            p2 = img[:, 1]\r\n            p3 = img[:, 2]\r\n            planes = [p1, p2, p3]\r\n        else:\r\n            planes = [img]\r\n\r\n    histogram = np.zeros(256 * d)\r\n    for i in np.arange(len(planes)):\r\n        p = planes[i]\r\n        for val in np.unique(p):\r\n            count = np.sum(p == val)\r\n            histogram[val + i * 256] = count\r\n    histogram = histogram / img.size\r\n    return histogram\r\n\r\n\r\ndef hist_compute_orb(image):\r\n    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8],\r\n                        [0, 256, 0, 256, 0, 256])\r\n    hist = cv2.normalize(hist, hist).flatten()\r\n    return hist\r\n\r\n\r\ndef entropy(histogram):\r\n    histogram = histogram[histogram > 0]\r\n    return -np.sum(histogram * np.log2(histogram))\r\n\r\n\r\ndef drawLabel(w, h, x, y, text, frame):\r\n    cv2.rectangle(frame, (x, y), (x + w, y + h), (120, 0, 0), 2)\r\n    cv2.putText(frame, text, (x + 20, y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\r\n\r\n\r\ndef showImageAndStop(name, im):\r\n    cv2.imshow(name, im)\r\n    cv2.waitKey()\r\n    cv2.destroyAllWindows()\r\n\r\n\r\ndef contourIntersect(contours, frame):\r\n    blank = np.zeros(frame.shape[0:2])\r\n    conts = []\r\n    intersection = []\r\n    for i in range(len(contours)):\r\n        for j in range(len(contours)):\r\n            if i != j:\r\n                checkcontours = [contours[i], contours[j]]\r\n                # Copy each contour into its own image and fill it with '1'\r\n                image1 = cv2.drawContours(blank.copy(), checkcontours, 0, 1)\r\n                image2 = cv2.drawContours(blank.copy(), checkcontours, 1, 1)\r\n\r\n                mat = cv2.bitwise_and(image1, image2)\r\n                intersection.append(mat)\r\n\r\n        for k in intersection:\r\n            if k.any():\r\n                intersection = []\r\n\r\n        if len(intersection) != 0:\r\n            conts.append(i)\r\n\r\n    return conts\r\n\r\n\r\ndef checkInside(rects, index):\r\n    new_index = []\r\n    for i in index:\r\n        for j in index:\r\n            if i != j:\r\n                x1, y1, w, h = rects[i]\r\n                x2, y2 = x1 + w, y1 + h\r\n                X, Y, W, H = rects[j]\r\n                if (x1 < X and X < x2) and (x1 < (X + W) and (X + W) < x2):\r\n                    if (y1 < Y and Y < y2) and (y1 < (Y + H) and (Y + H) < y2):\r\n                        new_index.append(j)\r\n\r\n    return new_index\r\n\r\n\r\ndef reduceListOuts(outs, rects, listindexfree):\r\n    out_ = []\r\n    rect_ = []\r\n    for i in range(len(outs)):\r\n        if i in listindexfree:\r\n            out_.append(outs[i])\r\n            rect_.append(rects[i])\r\n\r\n    return out_, rect_\r\n\r\n\r\ndef shrinkenCountoursList(hulls, frame, rects):\r\n    listindexfree = contourIntersect(hulls, frame)\r\n    listindexinside = checkInside(rects, listindexfree)\r\n    listindexfree = set(listindexfree) - set(listindexinside)\r\n    return listindexfree\r\n\r\n\r\ncam_maker = 'GOPRO'\r\ncam_model = 'HERO4 Silver'\r\nlens_maker = 'GOPRO'\r\nlens_model = 'fixed lens'\r\n\r\ndb = lensfunpy.Database()\r\ncam = db.find_cameras(cam_maker, cam_model)[0]\r\nlens = db.find_lenses(cam, lens_maker, lens_model)[0]\r\n\r\nfocal_length = 28.0\r\naperture = 1.4\r\ndistance = 10\r\ndef correct_distortion(frame, h, w):\r\n    # Definisci matrice telecamera K\r\n    '''\r\n    K = np.array([[[673.9683892, 0., 343.68638231],\r\n                   [0., 676.08466459, 245.31865398],\r\n                   [0., 0., 1.]]])\r\n\r\n    # Definisce i coefficienti di distorsione d\r\n    #d = np.array([5.44787247e-02, 1.23043244e-01, - 4.52559581e-04, 5.47011732e-03, - 6.83110234e-01])\r\n    d = np.array([0.3, 0.001, 0.0, 0.0, 0.01])\r\n\r\n    # Leggi un'immagine di esempio e acquisisci le sue dimensioni\r\n    # img = cv2.imread(\"calibrazione_campioni / 2016-07-13-124020.jpg\")\r\n    # h, w = img.shape[: 2]\r\n\r\n    # Genera nuova matrice telecamera dai parametri\r\n    # newcameramatrix, roi = cv2.getOptimalNewCameraMatrix(K, d, (w, h), 0)\r\n\r\n    # Genera tabelle di ricerca per rimappare l' immagine della telecamera\r\n\r\n    # mapx, mapy = cv2.initUndistortRectifyMap(K, d, None, newcameramatrix, (w, h), 5)\r\n\r\n    # Rimappa l'immagine originale in una nuova immagine\r\n    # newimg = cv2.remap(frame, mapx, mapy, cv2.INTER_LINEAR)\r\n\r\n    with Image(frame) as img:\r\n        #print(img.size)\r\n        img.virtual_pixel = 'transparent'\r\n        img.distort('barrel', -(0.2, 0.0, 0.0, 1.0))\r\n        # img.save(filename='checks_barrel.png')\r\n        # convert to opencv/numpy array format\r\n        img_opencv = np.array(img)\r\n    '''\r\n\r\n\r\n    #image_path = '/path/to/image.tiff'\r\n    #undistorted_image_path = '/path/to/image_undist.tiff'\r\n\r\n    #im = cv2.imread(image_path)\r\n    #height, width = im.shape[0], im.shape[1]\r\n\r\n    mod = lensfunpy.Modifier(lens, cam.crop_factor, w, h)\r\n    mod.initialize(focal_length, aperture, distance)\r\n\r\n    undist_coords = mod.apply_geometry_distortion()\r\n    im_undistorted = cv2.remap(frame, undist_coords, None, cv2.INTER_LANCZOS4)\r\n    return im_undistorted\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- utils.py	(revision 47fcd3de693926b54da2059408e3716cb1878001)
+++ utils.py	(date 1590326083738)
@@ -150,6 +150,8 @@
 distance = 10
 def correct_distortion(frame, h, w):
     # Definisci matrice telecamera K
+    print(cam)
+    print(lens)
     '''
     K = np.array([[[673.9683892, 0., 343.68638231],
                    [0., 676.08466459, 245.31865398],
Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import cv2\r\nimport numpy as np\r\nimport utils\r\nimport yolo\r\nimport detect\r\nimport rectify\r\nimport time\r\nfrom matplotlib import pyplot as plt\r\nfrom skimage.feature import hog\r\nfrom skimage import data, exposure\r\n\r\nvideo_stronzo = './videos/VIRB0391.MP4'\r\nvideo_normale = './videos/VIRB0414.MP4'\r\nvideo_tondo = './videos/GOPR2051.MP4'\r\nvideo_comune = './videos/VIRB0407.MP4'\r\nvideo_madonna_bimbo = './videos/VIRB0392.MP4'\r\nvideo_boh = \"./videos/VID_20180529_112440.mp4\"  # ci vuole gabor filter da 30\r\nvideo_comune_trim = \"./videos/trim.mp4\"\r\nvideo_trim = \"./videos/trimsss.mp4\"\r\nvideo_diverso = './videos/VIRB0415.MP4'\r\nvideo_gente = './videos/GOPR1940.MP4'\r\nvideo_1 = './videos/GOPR1928.MP4'\r\nvideo_2 = './videos/GOPR1947.MP4'\r\nvideo_3 = './videos/GOPR2039.MP4'\r\nvideo_nome_lungo = './videos/VID_20180529_112539.mp4'\r\nvideo_persone_s = './videos/trim_2.mp4'\r\nvideo_facce = \"./videos/20180206_114604.mp4\"\r\nvideo_sono_le_11 = './videos/IMG_4082.MOV'\r\nvideo_fish_eye = './videos/GOPR5818.MP4'  # da scaricare\r\nvideo_statua_fish_eye = './videos/GOPR5831.MP4'  # da scaricare\r\nvideo_statua_negra = \"./videos/IMG_7854.MOV\"\r\nvideo_statue_col = \"./videos/IMG_9630.MOV\"\r\nvideo_statue_white = \"./videos/IMG_4080.MOV\"\r\nvideo_statue_white_t = \"./videos/IMG_4080_Trim.mp4\"\r\nvideo_k = \"./videos/Nuovi/GOPR5827.MP4\"\r\nvideo_o = \"./videos/Nuovi/GOPR5825.MP4\"\r\nvideo_q = \"./videos/Nuovi/GOPR2049.MP4\"\r\nvideo_pi = \"./videos/Nuovi/IMG_9621.MOV\"\r\nvideo_a = \"./videos/Nuovi/IMG_9628.MOV\"\r\nvideo_b = \"./videos/Nuovi/IMG_4076.MOV\"\r\nvideo_d = \"./videos/Nuovi/IMG_4074.MOV\"\r\nuomo_cappello = \"./videos/Nuovi/IMG_2653.MOV\"\r\nvid = \"./videos/Nuovi/GOPR5828.MP4\"\r\nvideo_zoom = \"./videos/Nuovi/VID_20180529_112627.mp4\"\r\nvideo_largo = \"./videos/Nuovi/20180206_113800.mp4\"\r\nvideo_cornice = \"./videos/Nuovi/20180206_111931.mp4\"\r\nvideo_no_cornice = \"./videos/Nuovi/IMG_7852.MOV\"\r\nvideo_tipo = \"./videos/Nuovi/IMG_9622.MOV\"\r\nvideo_ll = \"./videos/Nuovi/VID_20180529_112706.mp4\"\r\nvideo_corridoio = \"./videos/Nuovi/VIRB0394.MP4\"\r\nvideo_distorto = \"./videos/GOPR5830.MP4\"\r\nvideo_rombi = \"./videos/GOPR5825.MP4\"\r\n\r\ncap = cv2.VideoCapture(video_rombi)\r\n\r\n\r\nif not cap.isOpened():\r\n    print(\"Unable to read camera feed\")\r\n\r\nframe_width = int(cap.get(3))\r\nframe_height = int(cap.get(4))\r\nout = cv2.VideoWriter('outpy.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (frame_width, frame_height))\r\n\r\nroom = \"Stanza generica\"\r\n\r\ntemplate1 = cv2.imread('./match/match1.jpg', cv2.IMREAD_COLOR)\r\ntemplate2 = cv2.imread('./match/match2.jpg', cv2.IMREAD_COLOR)\r\ntemplate3 = cv2.imread('./match/match3.jpg', cv2.IMREAD_COLOR)\r\ntemplate4 = cv2.imread('./match/match4.png', cv2.IMREAD_COLOR)\r\n\r\n\r\nwhile (True):\r\n    ret, frame = cap.read()\r\n\r\n    if ret:\r\n        frame = utils.correct_distortion(frame, frame_height, frame_width)\r\n\r\n        dict = []\r\n\r\n        # DETECTION\r\n        src = detect.hybrid_edge_detection_V2(frame)\r\n\r\n\r\n        # CONTOURS\r\n        rects, hulls, src_mask = detect.get_contours(src)\r\n\r\n\r\n        # estrae gli indici delle roi senza intersezioni e rimuove gli indici di roi contenute in altre roi\r\n        # utile per aumentare le performance e iterare solo su contorni certi\r\n        # riduzioni falsi positivi\r\n        listindexfree = utils.shrinkenCountoursList(hulls, frame, rects)\r\n\r\n        blank = np.zeros_like(frame)\r\n        for idk in listindexfree:\r\n            cv2.drawContours(blank, hulls, idk, (255, 255, 255), 1)\r\n\r\n        #utils.showImageAndStop('ROI', blank)\r\n\r\n        # CROP\r\n        outs, masks, green = detect.cropping_frame(frame, hulls, src_mask)\r\n\r\n        # riduzione effettiva della lista di contorni e rect tramite index calcolati\r\n        outs, rects = utils.reduceListOuts(outs, rects, listindexfree)\r\n        print(rects)\r\n\r\n        # FEATURE EXTRACTION\r\n        for idx in range(len(outs)):\r\n            hist = utils.compute_histogram(outs[idx])\r\n            # entropy = utils.entropy(hist)\r\n            # print(entropy)\r\n            hist0 = utils.hist_compute_orb(green[idx])\r\n\r\n            entropy = utils.entropy(hist0)\r\n            print(entropy)\r\n\r\n            # se è troppo piccolo scartalo\r\n            if outs[idx].shape[0] >= template3.shape[0]:\r\n\r\n                #utils.showImageAndStop(\"cropped\", outs[idx])\r\n                res1 = cv2.matchTemplate(outs[idx], template1, cv2.TM_CCORR_NORMED)\r\n                res2 = cv2.matchTemplate(outs[idx], template2, cv2.TM_CCORR_NORMED)\r\n                res3 = cv2.matchTemplate(outs[idx], template3, cv2.TM_CCORR_NORMED)\r\n                res4 = cv2.matchTemplate(outs[idx], template4, cv2.TM_CCORR_NORMED)\r\n\r\n                min_val1, max_val1, min_loc1, max_loc1 = cv2.minMaxLoc(res1)\r\n                min_val2, max_val2, min_loc2, max_loc2 = cv2.minMaxLoc(res2)\r\n                min_val3, max_val3, min_loc3, max_loc3 = cv2.minMaxLoc(res3)\r\n                min_val4, max_val4, min_loc4, max_loc4 = cv2.minMaxLoc(res4)\r\n                #utils.showImageAndStop(\"cropped\",outs[idx])\r\n                print(\"max match 1: {}\".format(max_val1))\r\n                print(\"max match 2: {}\".format(max_val2))\r\n                print(\"max match 3: {}\".format(max_val3))\r\n                print(\"max match 4: {}\".format(max_val4))\r\n\r\n                isBig = False\r\n                if outs[idx].shape[0] > 300 and outs[idx].shape[1] > 300:\r\n                    isBig = True\r\n\r\n                if entropy >= 1.3 and ((max_val1 <= 0.96 and max_val2 <= 0.96 and max_val3 <= 0.96) or isBig):\r\n\r\n                    # RECTIFICATION\r\n\r\n                    text, tmp = rectify.detectKeyPoints(outs[idx])\r\n                    if tmp != \"\":\r\n                        room = tmp\r\n                    imm = masks[idx]\r\n                    out_bin_pad = cv2.copyMakeBorder(imm, 50, 50, 50, 50, 0)\r\n                    out_imm_pad = cv2.copyMakeBorder(outs[idx], 50, 50, 50, 50, 0)\r\n                    corners = rectify.hougesLinesAndCorner(out_bin_pad)\r\n                    # utils.showImageAndStop(\"cropped\",out_imm_pad)\r\n\r\n                    if len(corners) == 4 and text == 'quadro':\r\n                        p = rectify.order_corners(corners)\r\n                        # se order_corners non dà errore\r\n                        if p != 0:\r\n                            warped = rectify.rectify_image_2(out_imm_pad.shape[0], out_imm_pad.shape[1], out_imm_pad, p)\r\n                            #se rectify_image_2 non dà errore\r\n                            if not np.isscalar(warped):\r\n                                text, tmp = rectify.detectKeyPoints(warped)\r\n                                if tmp != \"\":\r\n                                    room = tmp\r\n                    dict.append({'texts': text, 'rects': rects[idx]})\r\n                    \r\n\r\n        # PERSON\r\n\r\n        detected, rects_yolo, label_yolo = yolo.detect_person(frame, frame_height, frame_width)\r\n        frame, rects_dec_eyes = yolo.detect_eyes(frame, detected)\r\n\r\n\r\n        # codice per controllo/aggiunta/rimozione rettangoli oggetti detctetati\r\n        for r in range(0, len(rects_yolo)):\r\n            dict.append({'texts': label_yolo[r], 'rects': rects_yolo[r]})\r\n        for r in range(0, len(rects_dec_eyes)):\r\n            dict.append({'texts': 'statua', 'rects': rects_dec_eyes[r]})\r\n\r\n        kkk = dict[:]\r\n        kk = []\r\n        for a in kkk:\r\n            kk.append(a['rects'])\r\n\r\n        listindexyolo = list(range(0, len(dict)))\r\n        listindexnoinside_yolo = utils.checkInside(kk, listindexyolo)\r\n        listindexnoinside_yolo.sort()\r\n\r\n        for index in reversed(listindexyolo):\r\n            if index in listindexnoinside_yolo:\r\n                a=dict.pop(index)\r\n        # fine controllo/aggiunta/rimozione\r\n\r\n        for di in dict:\r\n            utils.drawLabel(di['rects'][2], di['rects'][3], di['rects'][0], di['rects'][1], di['texts'], frame)\r\n\r\n        #utils.showImageAndStop(\"detect\", frame)\r\n        # print(room)\r\n\r\n        k = cv2.waitKey(5) & 0xFF\r\n        if k == ord(\"q\"):\r\n            break\r\n\r\n        # Write the frame into the file 'output.avi'\r\n        out.write(frame)\r\n\r\n    # Break the loop\r\n    else:\r\n        break\r\n\r\n# When everything done, release the video capture and video write objects\r\ncap.release()\r\nout.release()\r\n\r\n# Closes all the frames\r\ncv2.destroyAllWindows()\r\ncv2.waitKey(1)\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- main.py	(revision 47fcd3de693926b54da2059408e3716cb1878001)
+++ main.py	(date 1590321093890)
@@ -160,7 +160,7 @@
                                 if tmp != "":
                                     room = tmp
                     dict.append({'texts': text, 'rects': rects[idx]})
-                    
+
 
         # PERSON
 
